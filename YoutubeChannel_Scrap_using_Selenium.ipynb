{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e860a96",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73576041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411208d",
   "metadata": {},
   "source": [
    "### Automating web page loading with Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c94ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://www.youtube.com/@JohnWatsonRooney/videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f491031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a4b80d",
   "metadata": {},
   "source": [
    "### Collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bde68a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This script I threw together saves me hours. 4,7 k vues il y a 11 jours\n",
      "2 Ways to add Logging to your Python Code 2,9 k vues il y a 4 semaines\n",
      "Browsers are Essential now? Scraping Amazon in 2023 5,5 k vues il y a 1 mois\n",
      "Avoid This Common Error When Learning Web Scraping 3,6 k vues il y a 1 mois\n",
      "Make Your Own CLI Tools to Extract Data with CLICK 4,3 k vues il y a 1 mois\n",
      "Add a Database to your Web Scraper - Full Code How to 5,8 k vues il y a 2 mois\n",
      "Who is FASTER? Scrapy vs GO vs ME 4,3 k vues il y a 2 mois\n",
      "Scrape .aspx sites with this method 3,4 k vues il y a 2 mois\n",
      "ASYNC too Fast? Sync too Slow? Use THIS 4,2 k vues il y a 2 mois\n",
      "Supercharge Your Scraper With ASYNC (here's how) 5,8 k vues il y a 3 mois\n",
      "Modern HTML Scraping with Pythons BEST Tools 7,5 k vues il y a 3 mois\n",
      "Large JSON Response from an API Call? Try This 3,9 k vues il y a 3 mois\n",
      "Are CLI Frameworks Worth it? Trying TYPER 2,9 k vues il y a 3 mois\n",
      "3 Ways To Scrape Infinite Scroll Sites with Playwright 7,7 k vues il y a 4 mois\n",
      "The Biggest Mistake I Made When Starting Freelancing 4,7 k vues il y a 4 mois\n",
      "Why I don't use the best Web Scraping Framework 7,6 k vues il y a 4 mois\n",
      "Web Scraping Made Easy Using this Method. 8,8 k vues il y a 5 mois\n",
      "You Should Make Your OWN HTTP Clients for APIs (Shopify x Python) 3,5 k vues il y a 5 mois\n",
      "How To Parse Data Scraped from SCRIPT tags 4,6 k vues il y a 5 mois\n",
      "Try THIS Simple Python Decorator (It's Super Useful) 6,2 k vues il y a 5 mois\n",
      "Don't Keep Requesting API Data, DO THIS! 8,5 k vues il y a 6 mois\n",
      "Scraping multiples websites with one Python script 12 k vues il y a 6 mois\n",
      "Automate your job with Python 34 k vues il y a 6 mois\n",
      "Web Scraping with GO... Easy AND Fast?! 7,2 k vues il y a 6 mois\n",
      "Web Scraping Methods You NEED to Know 9,7 k vues il y a 6 mois\n",
      "What's So Special About this Python Framework?! 8,7 k vues il y a 7 mois\n",
      "THIS is a better way to return scraped data. 5,7 k vues il y a 7 mois\n",
      "How To Scrape (almost) ANY Website with Python 25 k vues il y a 7 mois\n",
      "How to Use Recursion in Python for API Pagination 3,4 k vues il y a 8 mois\n",
      "Best Web Scraping Combo? Use These In Your Projects 33 k vues il y a 8 mois\n"
     ]
    }
   ],
   "source": [
    "videos = driver.find_elements(By.CLASS_NAME,'style-scope ytd-rich-grid-media')\n",
    "\n",
    "for video in videos:\n",
    "    title = video.find_element(By.XPATH, './/*[@id=\"video-title\"]').text\n",
    "    views = video.find_element(By.XPATH, './/*[@id=\"metadata-line\"]/span[1]').text\n",
    "    when = video.find_element(By.XPATH, './/*[@id=\"metadata-line\"]/span[2]').text\n",
    "    print(title, views, when)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66524744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save data videos in a dictionary, then we add data to a list with it we are going to create a dataframe\n",
    "videos = driver.find_elements(By.CLASS_NAME,'style-scope ytd-rich-grid-media')\n",
    "video_list =[]\n",
    "for video in videos:\n",
    "    title = video.find_element(By.XPATH, './/*[@id=\"video-title\"]').text\n",
    "    views = video.find_element(By.XPATH, './/*[@id=\"metadata-line\"]/span[1]').text\n",
    "    when = video.find_element(By.XPATH, './/*[@id=\"metadata-line\"]/span[2]').text\n",
    "    vid_item = {\n",
    "        'title':title,\n",
    "        'views': views,\n",
    "        'posted': when,\n",
    "    }\n",
    "    video_list.append(vid_item)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b08c0c",
   "metadata": {},
   "source": [
    "### Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0091e5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37e6d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Youtube_channel_scraped_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59b2fc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "      <th>posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This script I threw together saves me hours.</td>\n",
       "      <td>2,3 k vues</td>\n",
       "      <td>il y a 23 heures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2 Ways to add Logging to your Python Code</td>\n",
       "      <td>2,5 k vues</td>\n",
       "      <td>il y a 2 semaines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Browsers are Essential now? Scraping Amazon in...</td>\n",
       "      <td>5 k vues</td>\n",
       "      <td>il y a 3 semaines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Avoid This Common Error When Learning Web Scra...</td>\n",
       "      <td>3,4 k vues</td>\n",
       "      <td>il y a 1 mois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Make Your Own CLI Tools to Extract Data with C...</td>\n",
       "      <td>4,1 k vues</td>\n",
       "      <td>il y a 1 mois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Add a Database to your Web Scraper - Full Code...</td>\n",
       "      <td>5,6 k vues</td>\n",
       "      <td>il y a 1 mois</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title       views  \\\n",
       "0           0       This script I threw together saves me hours.  2,3 k vues   \n",
       "1           1          2 Ways to add Logging to your Python Code  2,5 k vues   \n",
       "2           2  Browsers are Essential now? Scraping Amazon in...    5 k vues   \n",
       "3           3  Avoid This Common Error When Learning Web Scra...  3,4 k vues   \n",
       "4           4  Make Your Own CLI Tools to Extract Data with C...  4,1 k vues   \n",
       "5           5  Add a Database to your Web Scraper - Full Code...  5,6 k vues   \n",
       "\n",
       "              posted  \n",
       "0   il y a 23 heures  \n",
       "1  il y a 2 semaines  \n",
       "2  il y a 3 semaines  \n",
       "3      il y a 1 mois  \n",
       "4      il y a 1 mois  \n",
       "5      il y a 1 mois  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Youtube_channel_scraped_data.csv')\n",
    "data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c3603",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
